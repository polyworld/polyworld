This file is a place to maintain cross-platform notes on experiments--naming
conventions, parameter selections, motivations, and maybe some results.  In
the early days I did this routinely, but fell out of practice, and now hope to
resume the practice.  -  larryy 3/12/07

Files marked _driven and _passive (adopting the terms used by McShea) related
to runs comparing complexity with and without natural selection (NS). I
believe worldfile_driven_original captures the original parameter set used for
these studies, though many permutations were tried.

_hard simply increases the high-population penalty (changes NumDepletionSteps
from 200 to 100)

_domains added two barriers and divided the world into three domains. This was
done in an attempt to make it more difficult for a solution to emerge and take
over the entire population (and delay the onset of maxPop), back when I
thought NS was selecting for complexity faster than genetic drift (GD), and
that driven complexity rose faster initially, but crossed over passive
complexity at approximately the time the population maxed out.  (I no longer
think this is what is going on.)  There was a problem with these runs, which
is that in order to make the emergence of a solution more difficult, sims
would tend to see the population plunge to its minimum, at which point either
the steady-state GA would kick in, thus contaminating the results with
evolution guided by the heuristic fitness function, or the low-population
advantage would produce immortal idiots (agents that live forever, but do not
produce sufficient or sufficiently varied offspring to ever get any better).
This problem was particularly driven by population minima within individual
domains--even after one or two domains had maximal populations, a low
population in one domain could continue to invoke the steady-state GA.
Hence...

_barriers uses two barriers (like _domains), but only one domain.  This fixed
the minPop / steady-state GA problem, and did delay the onset of maxPop.  It
even seemed to show driven complexity riding above passive complexity for a
longer time and still crossing over at about the time of maxPop.  So this
initially strongly supported the original thinking (that NS increased
complexity faster than GD).

_fixed and _fbs# are fixed-brain-size runs.  Observing a strong correlation
between brain size and complexity, I wanted to run some sims with fixed brain
sizes, and try to tease out other contributions to complexity growth.  The
fbs# runs were a particular suite of runs defined in the worldfiles_070301
files.  Only the first and last (majority of it anyway) runs were ever
performed.  They took enormous amounts of time and disk space, and priority
was given to the _df# runs once I realized what was actually going on in
these driven vs. passive runs (at least I think I understand them now--
complexity is going up at about the same rate in NS and GD until a solution
is achieved in the NS runs, at which point the population tends to widely
adopt this solution and mean complexity drops or levels off to the
corresponding solution's complexity, a kind of local optimum).

_df# runs (and the checked-in _dynfood worldfile) use "dynamic food patches". 
The patches turn on and off so food moves around the world, requiring the
agents to evolve a slightly more complex behavior and hopefully a measurable
increase in complexity of their neural dynamics.  Jury is still out on this
one.  I do get successful populations, though, with the agents still circling
furiously while they're in the active patch, but running fairly rapidly over
to the new patch when the food location shifts.  Not sure complexity is going
to be substantially different, however, since the number of neural groups
initially climbs faster (than static food patches), but eventually drops off
to about the same level, suggesting a pure stimulus-response solution was
found, albeit belatedly.

_df1 moves the food too quickly (every 50 time steps), so a good enough
strategy was to wander aimlessly and wait for the food to come to you.

_df2 moves the food every 200 time steps--approximately the mean lifespan of
the agents (why is this so low, given the max lifespan ranging from 500 to
1000?).  It achieved populations that successfully followed the food.  But
their driven complexity was hardly any different from that of agents in the
static food world.

_df3 will attempt to isolate the food partially by barriers, to see if it is
possible to evolve something more complicated than a simplel stimulus-response
behavior.  Given the large swings in population evidenced in _df2, I have
doubts about whether a successful population will evolve (but, then, I had
doubts about their ability to evolve to follow dynamic food patches, and that
was achieved fairly easily). ... As feared, barriers blocking all view of the
food failed to produce anything of value, complexity-wise.  Interestingly, the
cycle I picked was *just* fast enough that agents did populate one of the
three barrier-separated regions.  They'd almost die out, then the food would
come back, and they'd procreate like crazy, reaching the maximum population,
then the food would go away and numbers would crash. Interesting cycle, but
not what we're looking for.  (Although I am curious to see if the repeated
population bottlenecks produced anything substantially different than a normal
run.)

_df4 uses another new capability--dynamic barriers.  The setup is like _df3,
but the barriers start out at zero depth and gradually grow in, reaching 60%
of the depth of the world (the food goes to 50% of the depth of the world)
only after 30,000 time steps.  The idea is to introduce the barriers slowly,
so critters can first evolve to follow the food, then evolve the ability to
circumvent the barriers.  Still no guarantee they'll get there, of course, but
at least now there's hope.  Nope.  _df4 seemed to come close, but ultimately
produced agents that just sat and waited for the food to come to them.  So...

In _df2, the overall period was 800 steps, and food spent 200 steps in each
site (there were four sites).  Agents migrated nicely.

In _df4, the overall period was 600 steps, and food spent 200 steps in each
site (there were only three sites).  Agents ended up waiting for the food to
come to them.

In _df5, the overall period is 900 steps, with food spending 300 steps in each
site (still three sites).  I think that will tip the scales.  We'll see.  I
also increased the high-population penalty (reduced NumDepletionSteps from 150
to 100), because they were so successful at reproducing that while there ended
up being 23294 agents born, there were 94766 birth-denials.  I don't like that
ratio at all.  (Smite is still turned off.)  I think this is one of the
reasons the wait-for-it solution so completely wiped out the run-to-it
solution, even though both were evident for a while in df4.

_df5 produced migrating agents until the barrier became too long.  Agents
never learned to go around it effectively, finally settling for waiting for
the food to come to them.  (The low-population-advantage makes this possible,
by reducing energy consumption and even extending life as the population
reaches a minimum.)

_df6 is like _df2 (4 patches, in the corners, each lasting for 200 steps of
an 800 step cycle), but has a barrier that grows between two of the patches.
However, it doesn't start growing for 10K steps, by which time I know a
stable migrating pattern has emerged from the _df2 run, and then it grows to
just 40% of the world's depth (rather than 60% as in _df4 and _df5) by
t=30K steps.  Maybe this will let them retain their migrating pattern and
just get better at it.  If this doesn't work, I'm not sure what else to try.
_df6 is running on Aden 3/16/07.

(I am also running _df5 again with spiking neurons, just for the heck of it,
on Pinky, while I wait to see what _df6 does and try to think about where to
go next.)

During the various df# runs, I also ran simple driven and passive runs with
a lower mutation rate.  These _low_mrate runs demonstrated a stability to the
relation between the early phases of driven and passive complexity growth.
Both went at about the same rate, but at a slower rate than in the higher
mutation rate runs.  They ultimately joined up with the higher mutation rate
curves, just taking longer to get there.  Of mild interest is the fact that
a complexity-as-fitness run with a lower mutation rate reached an even higher
level of complexity than the complexity-as-fitness run with the original
higher mutation rate.

_df6 also had problems with the barrier, but not as much, of course, since it
didn't quite cut off all access to the food.  Some of the agents seemed to
just be finding the patch on the other side of the barrier when the food
moved again.  So I am trying...

_df7 is like _df6, except the food stays in each location twice as long.  So
the total cycle is 1600 steps, instead of 800 steps.

_df8 and its various manifestations (also known as df?) are like df4, except
the barriers are static for 10K steps, and then grow in (to 40% of the world)
by 30K steps.  Food is in three dynamic patches with an overall period of 900.
Various experiments were run with this configuration including LightAsYaw,
TauNN, Complexity_F30, and Complexity_F30_P-I.  _df8 used population numbers
that largely avoided the bottleneck and inadvertantly routinely mutated the
seeds.

_df9 is like _df8, but using a new parameter, EatMateSpan, which specified the
amount of time after having last eaten that an agent is allowed to mate.  In
all previous runs this has effectively been infinite.  _df9 uses 50.  This was
done in an attempt to favor selection of agents that migrated to dynamic food
patches rather than waiting for the food to come around or nearby again.  I
also eliminated the mutation of the seed population.
